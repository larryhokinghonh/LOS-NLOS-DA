{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Classification and Regression\n",
    "\n",
    "This notebook handles data preprocessing tasks, which are essential before training machine learning models. The main steps include:\n",
    "\n",
    "- Loading the dataset\n",
    "- Separating features and targets for classification and regression\n",
    "- Splitting the data into training and testing sets\n",
    "- Selecting top features for modeling\n",
    "- Scaling the data using `RobustScaler`\n",
    "\n",
    "The preprocessed data is saved for further use in model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import joblib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Target Separation\n",
    "\n",
    "The dataset is loaded using `pandas.read_csv()`. Features (`X`) are separated from the classification target (`NLOS`) and regression target (`RANGE`). This distinction allows for both classification and regression tasks to be performed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/processed/aggregated_dataset.csv')\n",
    "X = data.drop(columns=['NLOS', 'RANGE'])  # Features\n",
    "y_class = data['NLOS']                    # Classification target\n",
    "y_reg = data['RANGE']                     # Regression target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data into Training and Testing Sets\n",
    "\n",
    "The dataset is split using `train_test_split` from `sklearn`. A stratified split is used to maintain the class distribution in both the training and test sets. This ensures balanced representation of classes in classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_class_train, y_class_test, y_reg_train, y_reg_test = train_test_split(\n",
    "    X, y_class, y_reg, \n",
    "    test_size=0.2, \n",
    "    stratify=y_class,  \n",
    "    random_state=42     \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "A set of top-performing features is selected for model training. These features are stored in the `top_features` list. Feature selection helps reduce model complexity and improves performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial features set\n",
    "top_features = [\n",
    "    'RXPACC', 'FP_AMP1', 'FP_AMP2', 'FP_AMP3', \n",
    "    'RISE_TIME_CLIPPED', 'CIR_SKEW', \n",
    "    'CIR_ENERGY_FIRST_100', 'CIR_PWR', 'FP_IDX'\n",
    "]\n",
    "\n",
    "X_train_top = X_train[top_features]\n",
    "X_test_top = X_test[top_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaling using RobustScaler\n",
    "\n",
    "`RobustScaler` is used to scale the selected features. Unlike other scalers, it is robust to outliers by using the median and interquartile range (IQR) for scaling. This ensures that extreme values do not dominate the scaling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_train_top= scaler.fit_transform(X_train_top)\n",
    "X_test_top= scaler.transform(X_test_top)\n",
    "\n",
    "# Save the scaled top features\n",
    "np.save('../data/processed/X_train_top.npy', X_train_top)\n",
    "np.save('../data/processed/X_test_top.npy', X_test_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated features set\n",
    "top_features = [\n",
    "    'RXPACC', 'CIR_ENERGY_FIRST_100', 'RISE_TIME_CLIPPED', 'RISE_TIME', \n",
    "    'CIR742', 'CIR741', 'CIR574', 'CIR740', 'CIR326', 'CIR646', 'CIR582', 'CIR575', \n",
    "    'CIR246', 'CIR526', 'CIR654', 'CIR350', 'CIR590', 'CIR430'\n",
    "]\n",
    "\n",
    "X_train_top_scaled = X_train[top_features]\n",
    "X_test_top_scaled = X_test[top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_train_top_scaled = scaler.fit_transform(X_train_top_scaled)\n",
    "X_test_top_scaled = scaler.transform(X_test_top_scaled)\n",
    "\n",
    "# Save the scaled top features\n",
    "np.save('../data/processed/X_train_top_scaled.npy', X_train_top_scaled)\n",
    "np.save('../data/processed/X_test_top_scaled.npy', X_test_top_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # Option A: PCA on all features \n",
    "# pca = PCA(n_components=0.95)  # Retain 95% variance\n",
    "# X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "# X_test_pca = pca.transform(X_test_scaled)\n",
    "# print(f\"PCA reduced dimensions to {X_train_pca.shape[1]} components.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pca was not effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets (raw, no scaling)\n",
    "# classification\n",
    "np.save('../data/processed/y_class_train.npy', y_class_train) \n",
    "np.save('../data/processed/y_class_test.npy', y_class_test)\n",
    "\n",
    "# Save regression targets\n",
    "np.save('../data/processed/y_reg_train.npy', y_reg_train)\n",
    "np.save('../data/processed/y_reg_test.npy', y_reg_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
